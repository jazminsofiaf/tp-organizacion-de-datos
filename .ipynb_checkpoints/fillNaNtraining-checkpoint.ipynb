{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "propertytype = {}\n",
    "propertytype[0] = 0\n",
    "propertytype[\"appartment\"] = 1\n",
    "propertytype[\"apartment\"] = 1\n",
    "propertytype[\"departamento\"] = 1\n",
    "propertytype[\"house\"] = 2\n",
    "propertytype[\"casa\"] = 2\n",
    "propertytype[\"PH\"] = 3\n",
    "propertytype[\"ph\"] = 3\n",
    "propertytype[\"store\"] = 4\n",
    "propertytype[\"local\"] = 4\n",
    "\n",
    "def date_to_float(dt64):\n",
    "    return (dt64 - np.datetime64('2013-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "\n",
    "\n",
    "def define_category(d):\n",
    "    if(\"picina\" in d or \"garage\" in d):\n",
    "        return 25\n",
    "\n",
    "    if(\"pileta\" in d or \"cochera\" in d):\n",
    "        return 20\n",
    "\n",
    "    if(\"gimnasio\" in d):\n",
    "        return 15\n",
    "    \n",
    "    if(\"sum\" in d):\n",
    "        return 10\n",
    "    \n",
    "    if(\"reciclar\" in d or \"refaccionar\" in d ):\n",
    "        return -20\n",
    "    return 0\n",
    "   \n",
    "\n",
    "def fill_nan_and_convert_to_float(datos):\n",
    "    columns = ['created_on','property_type','lat','lon', 'place_name','state_name',\n",
    "                 'surface_total_in_m2','surface_covered_in_m2','description',\n",
    "                 'floor','rooms','expenses', 'price_aprox_usd','price_usd_per_m2']\n",
    "   \n",
    "    datos = datos.loc[:,columns]\n",
    "    \n",
    "    #para el tamaño total de la propiedad uso el promedio\n",
    "    datos[\"surface_total_in_m2\"] = datos['surface_total_in_m2'].fillna(datos['surface_total_in_m2'].mean())\n",
    "    #tamaño cubierto, tomo el total de la fila\n",
    "    datos[\"surface_covered_in_m2\"] = datos['surface_covered_in_m2'].fillna(datos['surface_total_in_m2'])\n",
    "  \n",
    "    \n",
    "    #relleno el piso y las habitaciones con la moda\n",
    "    datos[\"floor\"] = datos['floor'].fillna(datos.dropna(subset=['floor']).floor.value_counts().idxmax())\n",
    "    datos[\"rooms\"] = datos['rooms'].fillna(datos.dropna(subset=['rooms']).rooms.value_counts().idxmax())\n",
    "    \n",
    "    #tipo de propiedad\n",
    "    datos[\"property_type\"] = datos.property_type.map(lambda t: propertytype.get(t))\n",
    "    \n",
    "    #descripcion\n",
    "    datos[\"description\"] = datos.description.map(lambda d: define_category(str(d)))\n",
    "    \n",
    "    \n",
    "    #fecha\n",
    "    datos[\"created_on\"] =  pd.to_datetime(datos['created_on'])\n",
    "    datos['created_on'] = datos['created_on'].map(lambda dt64 :date_to_float(dt64))\n",
    "    \n",
    "    #barrios a numeros\n",
    "    datos[\"place_name\"] = pd.Categorical(datos.place_name)\n",
    "    datos[\"place_name\"] = datos.place_name.cat.codes\n",
    "    \n",
    "    #zonas a numeros\n",
    "    datos[\"state_name\"] = pd.Categorical(datos.state_name)\n",
    "    datos[\"state_name\"] = datos.state_name.cat.codes\n",
    "    \n",
    "    #latitud y longitud la relleno con el promedio del barrio\n",
    "    datos['lat'] = datos.groupby('place_name')['lat'].apply(lambda x: x.fillna(x.mean()))\n",
    "    datos['lon'] = datos.groupby('place_name')['lon'].apply(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    \n",
    "     #si en el campo de las expensas dice no, entonces le asigno expensas cero\n",
    "    datos[\"expenses\"] = datos[\"expenses\"].map(lambda exp: \"0\" if(re.search(str(exp), 'no', re.IGNORECASE)) else str(exp))\n",
    "                                                            \n",
    "    #si no tiene un valor numerico lo cambio a nan para luego asignarle el promedio del barrio                                                   \n",
    "    datos[\"expenses\"] = datos[\"expenses\"].map(lambda exp: re.sub(\"[^0-9]\", \"\",str(exp) ))\n",
    "    datos[\"expenses\"] = datos[\"expenses\"].map(lambda exp: np.NaN if(str(exp)== \"\") else exp)\n",
    "    datos[\"expenses\"] = datos[\"expenses\"].map(lambda exp: float(exp))\n",
    "    datos[\"expenses\"] = datos.groupby('place_name')['expenses'].apply(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    #precios\n",
    "    datos['price_aprox_usd'] = datos['price_aprox_usd'].map(lambda p: float(p))\n",
    "    datos['price_usd_per_m2'] = datos['price_usd_per_m2'].map(lambda p: float(p))\n",
    "   \n",
    "    #por si queda algun nan\n",
    "    datos.fillna(0, inplace=True)\n",
    "    \n",
    "    return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_signs(text):\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in text])\n",
    "def delete_accent_mark(s):\n",
    "    return ''.join((c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn'))\n",
    "\n",
    "def unificate_description(d):\n",
    "    if(pd.notnull(d)):\n",
    "        return delete_signs(delete_accent_mark(d).lower())\n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lista con todos los barrios posibles sin repetir (sin tildes y en minuscula)\n",
    "def get_neighborhoods(properati_df,nombre_conj_barios):\n",
    "    neighborhoods = properati_df[pd.notnull(properati_df['place_name'])].place_name\n",
    "    neighborhoods = neighborhoods.drop_duplicates(keep='first')\n",
    "    neighborhoods = neighborhoods.map(lambda b: delete_accent_mark(b).lower())\n",
    "    neighborhoods.replace(nombre_conj_barios, \"sin barrio\", inplace = True)\n",
    "    return neighborhoods\n",
    "\n",
    "\n",
    "\n",
    "def get_place_name(data):\n",
    "    places =[]\n",
    "    for index, row in data.iterrows():\n",
    "        if(pd.notnull(row['place_name_y']) and (row['place_name_y']!=\"sin barrio\") ):\n",
    "            places.append(row['place_name_y'].title())\n",
    "        else:\n",
    "            if(pd.notnull(row['place_name_x'])):\n",
    "                places.append(row['place_name_x'].title())\n",
    "            else:\n",
    "                places.append(row['place_name_x'])\n",
    "    return places\n",
    "\n",
    "\n",
    "\n",
    "def assign_neighborhoods(description,neighborhoods):\n",
    "    for neighborhood in neighborhoods:\n",
    "        if(str(description.encode('utf-8')).find(neighborhood) >= 0):\n",
    "              return neighborhood\n",
    "    return \"sin barrio\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def guess_neighborhoods(df,  nombre_conj_barios):\n",
    "    \n",
    "    neighborhoods = get_neighborhoods(df,nombre_conj_barios)\n",
    "\n",
    "    sin_barrio = df.loc[df.place_name.str.contains(nombre_conj_barios , na=False),:]\n",
    "    sin_barrio.place_name = sin_barrio.description.map(lambda description: assign_neighborhoods(description,neighborhoods))\n",
    "\n",
    "    \n",
    "    barrio_asignado = sin_barrio.loc[sin_barrio.place_name.str.contains(\"sin barrio\", na=False) == False,:]\n",
    "    \n",
    "    #columnas_no_price = ['id', 'created_on', 'property_type', 'operation',\n",
    "    #   'place_with_parent_names', 'country_name', 'state_name',\n",
    "    #   'lat-lon', 'lat', u'lon', 'surface_total_in_m2',\n",
    "    #   'surface_covered_in_m2', 'floor', 'rooms', 'expenses',\n",
    "    #   'description']\n",
    "    \n",
    "    columnas_no_price =['country_name','created_on','currency','description',\n",
    "       'expenses','extra','floor', 'geonames_id','id',\n",
    "       'image_thumbnail', 'lat', 'lat-lon', 'lon', 'operation',\n",
    "        'place_with_parent_names', 'price',\n",
    "       'price_aprox_local_currency', 'price_aprox_usd', 'price_per_m2',\n",
    "       'price_usd_per_m2', 'properati_url', 'property_type', 'rooms',\n",
    "       'state_name', 'surface_covered_in_m2', 'surface_in_m2',\n",
    "       'surface_total_in_m2','title']\n",
    "    \n",
    "    \n",
    "    properati_barrios = pd.merge(df, barrio_asignado,how='outer', on=columnas_no_price)\n",
    "    \n",
    "    properati_barrios['place_name']= get_place_name(properati_barrios)\n",
    "    columnas_no_price.append('place_name')\n",
    "    properati_barrios=properati_barrios.loc[:,columnas_no_price]\n",
    "    \n",
    "    return properati_barrios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df_properati_to_predict(df, file_name):\n",
    "\n",
    "    df.description = df.description.map(lambda d: unificate_description(d))\n",
    "    \n",
    "    guess_neighborhoods(df,\"Capital Federal\")\n",
    "    guess_neighborhoods(df,\"Buenos Aires Interior\")\n",
    "    \n",
    "    fill_nan_and_convert_to_float(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaz/fiuba/orga-de-datos-7506/lib/python2.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'state_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e3c9f04371e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mproperati_filtered\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../tp1/properati_filtered1.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_df_properati_to_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperati_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nada'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-617cba6377a3>\u001b[0m in \u001b[0;36mget_df_properati_to_predict\u001b[0;34m(df, file_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mguess_neighborhoods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Buenos Aires Interior\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfill_nan_and_convert_to_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-1d05bd59d33a>\u001b[0m in \u001b[0;36mfill_nan_and_convert_to_float\u001b[0;34m(datos)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m#zonas a numeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jaz/fiuba/orga-de-datos-7506/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2969\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2970\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'state_name'"
     ]
    }
   ],
   "source": [
    "properati_filtered= pd.read_csv('../tp1/properati_filtered1.csv',encoding='UTF-8')\n",
    "get_df_properati_to_predict(properati_filtered, 'nada')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "properati_filtered.to_csv('data_filled_ready_to_train.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
