{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K - Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viendo info. que aporta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_train.csv')\n",
    "train_set = train_set.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "       'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "       'rooms', 'expenses','price_aprox_usd']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FINAL RESULT:\n",
      "\tCluster 1\n",
      "\t\tNumber Points in Cluster 13903\n",
      "\t\tCentroid: [  1.38492812e+08   1.49910091e+00  -3.45568553e+01  -5.85267808e+01\n",
      "   2.96869237e+02   1.64834928e+00   1.78975689e+02   1.22892397e+02\n",
      "   1.03265482e+01   1.40868877e+00   2.88211177e+00   2.88593550e+04\n",
      "   2.38510476e+05]\n",
      "\tCluster 2\n",
      "\t\tNumber Points in Cluster 9432\n",
      "\t\tCentroid: [  1.10581704e+08   1.58259118e+00  -3.44925866e+01  -5.85927125e+01\n",
      "   3.05812871e+02   1.36842663e+00   2.14042515e+02   1.34501484e+02\n",
      "   1.10660517e+01   1.49840967e+00   3.01558524e+00   2.93707159e+04\n",
      "   2.55884573e+05]\n",
      "\tCluster 3\n",
      "\t\tNumber Points in Cluster 13887\n",
      "\t\tCentroid: [  1.22518373e+08   1.55332325e+00  -3.45456443e+01  -5.85112529e+01\n",
      "   3.03965723e+02   1.67941240e+00   1.97703320e+02   1.32972204e+02\n",
      "   1.05609563e+01   1.26391589e+00   2.93267084e+00   2.96892707e+04\n",
      "   2.57855691e+05]\n",
      "\tCluster 4\n",
      "\t\tNumber Points in Cluster 4492\n",
      "\t\tCentroid: [  9.76609667e+07   1.61731968e+00  -3.44687052e+01  -5.86057217e+01\n",
      "   2.95801425e+02   1.34973286e+00   2.56761131e+02   1.36456367e+02\n",
      "   1.12143811e+01   1.47284061e+00   2.95102404e+00   2.81955920e+04\n",
      "   2.41738815e+05]\n",
      "\tCluster 5\n",
      "\t\tNumber Points in Cluster 10431\n",
      "\t\tCentroid: [  1.28577496e+08   1.51404467e+00  -3.44952633e+01  -5.85632390e+01\n",
      "   2.93555747e+02   1.57482504e+00   1.99315885e+02   1.30099223e+02\n",
      "   1.07779695e+01   1.33515483e+00   2.92119643e+00   2.86719059e+04\n",
      "   2.54326011e+05]\n",
      "\tCluster 6\n",
      "\t\tNumber Points in Cluster 8036\n",
      "\t\tCentroid: [  1.03539003e+08   1.59245893e+00  -3.44660033e+01  -5.85953661e+01\n",
      "   2.96022150e+02   1.41015431e+00   2.27678820e+02   1.32230587e+02\n",
      "   1.04262071e+01   1.51592832e+00   3.02824788e+00   2.72131937e+04\n",
      "   2.42321019e+05]\n",
      "\tCluster 7\n",
      "\t\tNumber Points in Cluster 7184\n",
      "\t\tCentroid: [  1.16396651e+08   1.58143096e+00  -3.45356064e+01  -5.85525122e+01\n",
      "   2.98379315e+02   1.40200445e+00   2.17165924e+02   1.29521019e+02\n",
      "   1.07071269e+01   1.41258352e+00   3.01559020e+00   2.91594296e+04\n",
      "   2.49424660e+05]\n",
      "\tCluster 8\n",
      "\t\tNumber Points in Cluster 11292\n",
      "\t\tCentroid: [  1.33562204e+08   1.46236273e+00  -3.45744041e+01  -5.85306769e+01\n",
      "   2.93891782e+02   1.83156217e+00   1.83048530e+02   1.18144616e+02\n",
      "   1.10157634e+01   1.81987248e+00   2.90595112e+00   2.83242908e+04\n",
      "   2.40533270e+05]\n"
     ]
    }
   ],
   "source": [
    "N_CLUSTERS = 8 ; MAX_ITER = 500\n",
    "def print_results(centroids, num_cluster_points):\n",
    "    print('\\n\\nFINAL RESULT:')\n",
    "    for i, c in enumerate(centroids):\n",
    "        print('\\tCluster %d' % (i + 1))\n",
    "        print('\\t\\tNumber Points in Cluster %d' % num_cluster_points.count(i))\n",
    "        print('\\t\\tCentroid: %s' % str(centroids[i]))\n",
    "\n",
    "\n",
    "\n",
    "# Object KMeans\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=N_CLUSTERS, init=\"k-means++\", n_init=10, max_iter=MAX_ITER, tol=0.0001, \n",
    "                precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans.fit(train_set)\n",
    "\n",
    "# Obtenemos centro y numero de cluster para cada punto\n",
    "centroids = kmeans.cluster_centers_\n",
    "num_cluster_points = kmeans.labels_.tolist()\n",
    "print_results(centroids, num_cluster_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([27770, 27771, 27772, ..., 78654, 78655, 78656], dtype=int64),\n",
       " 1: array([ 4141,  4142,  4143, ..., 50000, 50001, 50010], dtype=int64),\n",
       " 2: array([10557, 10558, 10559, ..., 60502, 60503, 60504], dtype=int64),\n",
       " 3: array([    0,     1,     2, ..., 38745, 38746, 38750], dtype=int64),\n",
       " 4: array([16571, 16572, 16573, ..., 65954, 65955, 65956], dtype=int64),\n",
       " 5: array([ 1364,  1365,  1366, ..., 42681, 42682, 42683], dtype=int64),\n",
       " 6: array([ 7909,  7910,  7911, ..., 55006, 55007, 55008], dtype=int64),\n",
       " 7: array([21259, 21260, 21261, ..., 71971, 71973, 71974], dtype=int64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "dic_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando hiper - parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in (200, 300, 500, 800):\n",
    "    for z in (2,4,6,8,10,11,13, 15, 17, 19):\n",
    "        total = 0\n",
    "        cantidad = 0\n",
    "        # Object KMeans\n",
    "        kmeans = sklearn.cluster.KMeans(n_clusters=z, init=\"k-means++\", n_init=10, max_iter=x, tol=0.0001, \n",
    "                        precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "        # Calculate Kmeans\n",
    "        kmeans.fit(train_set)\n",
    "\n",
    "        dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "\n",
    "        print(\"ANALISIS CON \"+str(z)+\" clusters y \"+ str(x)+\" COMO MAX ITERACION:\")\n",
    "        for i in range(z):\n",
    "            puntos_cluster = dic_clusters[i]\n",
    "            #Creo dataset auxiliar\n",
    "            df = pd.DataFrame(columns=['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses', 'price_aprox_usd', 'price_usd_per_m2'])\n",
    "    \n",
    "            for j in range(0,len(puntos_cluster)):\n",
    "                df.loc[j] = train_set.loc[puntos_cluster[j]]\n",
    "        \n",
    "            df_to_predict = df[int(len(df)*0.7):]\n",
    "            real_prediction = df_to_predict.price_aprox_usd\n",
    "            df_to_predict = df_to_predict.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "            X_train = df[:int(len(df)*0.7)]\n",
    "            Y_train = X_train.price_aprox_usd\n",
    "            X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "    \n",
    "            prediccion = linear_regression(df_to_predict, X_train, Y_train)\n",
    "            precision = mean_squared_error(real_prediction, prediccion)\n",
    "            print(\"Precision con el cluster \"+ str(i) +\":\", precision )\n",
    "            cantidad += precision\n",
    "            total += 1\n",
    "        \n",
    "        print(\"PROMEDIO: \"+ str(cantidad/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means: predicciones por clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Función a usar para predecir\n",
    "def linear_regression(df_to_predict, x_train, y_train):\n",
    "    scaler = StandardScaler()\n",
    "    x_train_standarized =scaler.fit_transform(x_train)\n",
    "    X_standarized = scaler.fit_transform(df_to_predict)\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(x_train_standarized,y_train)\n",
    "    y_price_usd_predicted = regr.predict(X_standarized)\n",
    "    return y_price_usd_predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means + lineal regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hago K-means para el dataset de entrenamiento\n",
    "train_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_train.csv')\n",
    "train_set = train_set.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "       'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "       'rooms', 'expenses','price_aprox_usd']]\n",
    "\n",
    "# Object KMeans\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=6, init=\"k-means++\", n_init=10, max_iter=500, tol=0.0001, \n",
    "                        precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans.fit(train_set)\n",
    "\n",
    "dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "\n",
    "#Hago K-means para el dataset de validación\n",
    "predict_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_predict.csv')\n",
    "predict_set2 = predict_set.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "       'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "       'rooms', 'expenses']]\n",
    "predict_set_aux = predict_set2\n",
    "\n",
    "import numpy as np\n",
    "def setear_en_cero(row): return 0\n",
    "#Columna que luego será llenada con las predicciones\n",
    "predict_set_aux['prediccion'] = predict_set_aux.apply(lambda row: setear_en_cero(row),axis=1)\n",
    "\n",
    "# Object KMeans\n",
    "kmeans2 = sklearn.cluster.KMeans(n_clusters=6, init=\"k-means++\", n_init=10, max_iter=500, tol=0.0001, \n",
    "                        precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans2.fit(predict_set2)\n",
    "\n",
    "dic_clusters_predict = {i: np.where(kmeans2.labels_ == i)[0] for i in range(kmeans2.n_clusters)}\n",
    "\n",
    "#Una vez que se los clusters de cada dato extraigo del dataset de entrenamiento los datos del cluster 0 y los uso para predecir\n",
    "#los datos del dataset de predicción pertenecientes también al cluster 0. Luego repito procedimiento para cada cluster.\n",
    "for clave in dic_clusters:\n",
    "    \n",
    "    #Creación de datasets donde se almacenarán los datos de cada dataset pertenecientes a determinado cluster (según la iteración)\n",
    "    df = pd.DataFrame(columns=['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','price_aprox_usd'])\n",
    "    df2 = pd.DataFrame(columns=['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses'])\n",
    "    \n",
    "    for j in range(0,len(dic_clusters[clave])):\n",
    "        df.loc[j] = train_set.loc[dic_clusters[clave][j]]\n",
    "        \n",
    "    print(dic_clusters_predict, len(dic_clusters_predict[clave]))\n",
    "    for k in range(0,len(dic_clusters_predict[clave])):\n",
    "        df2.loc[k] = predict_set2.loc[dic_clusters_predict[clave][k]]\n",
    "    \n",
    "    df_to_predict = df2.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "       \n",
    "    X_train = df\n",
    "    Y_train = X_train.price_aprox_usd\n",
    "    X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "\n",
    "    total_predicciones= linear_regression(df_to_predict, X_train, Y_train)\n",
    "            \n",
    "    i = 0\n",
    "\n",
    "    for punto in dic_clusters_predict[clave]:\n",
    "        if i < len(total_predicciones):\n",
    "            predict_set_aux.loc[punto, 'prediccion'] = total_predicciones[i]\n",
    "        i += 1\n",
    "#Reabro el csv para obtener los ids        \n",
    "predict_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_predict.csv')\n",
    "ids = predict_set.id\n",
    "predicciones = predict_set_aux.prediccion\n",
    "resultado = pd.DataFrame({'id': ids, 'price_usd' : predicciones})\n",
    "resultado.to_csv(\"prediccion2.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means + random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hago K-means para el dataset de entrenamiento\n",
    "train_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_train.csv')\n",
    "train_set = train_set.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "       'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "       'rooms', 'expenses','price_aprox_usd']]\n",
    "\n",
    "# Object KMeans\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=6, init=\"k-means++\", n_init=10, max_iter=500, tol=0.0001, \n",
    "                        precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans.fit(train_set)\n",
    "\n",
    "dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "\n",
    "#Hago K-means para el dataset de validación\n",
    "predict_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_predict.csv')\n",
    "predict_set2 = predict_set.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "       'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "       'rooms', 'expenses']]\n",
    "predict_set_aux = predict_set2\n",
    "\n",
    "import numpy as np\n",
    "def setear_en_cero(row): return 0\n",
    "#Columna que luego será llenada con las predicciones\n",
    "predict_set_aux['prediccion'] = predict_set_aux.apply(lambda row: setear_en_cero(row),axis=1)\n",
    "\n",
    "# Object KMeans\n",
    "kmeans2 = sklearn.cluster.KMeans(n_clusters=6, init=\"k-means++\", n_init=10, max_iter=500, tol=0.0001, \n",
    "                        precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans2.fit(predict_set2)\n",
    "\n",
    "dic_clusters_predict = {i: np.where(kmeans2.labels_ == i)[0] for i in range(kmeans2.n_clusters)}\n",
    "\n",
    "#Una vez que se los clusters de cada dato extraigo del dataset de entrenamiento los datos del cluster 0 y los uso para predecir\n",
    "#los datos del dataset de predicción pertenecientes también al cluster 0. Luego repito procedimiento para cada cluster.\n",
    "for clave in dic_clusters:\n",
    "    \n",
    "    #Creación de datasets donde se almacenarán los datos de cada dataset pertenecientes a determinado cluster (según la iteración)\n",
    "    df = pd.DataFrame(columns=['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','price_aprox_usd'])\n",
    "    df2 = pd.DataFrame(columns=['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses'])\n",
    "    \n",
    "    for j in range(0,len(dic_clusters[clave])):\n",
    "        df.loc[j] = train_set.loc[dic_clusters[clave][j]]\n",
    "        \n",
    "    print(dic_clusters_predict, len(dic_clusters_predict[clave]))\n",
    "    for k in range(0,len(dic_clusters_predict[clave])):\n",
    "        df2.loc[k] = predict_set2.loc[dic_clusters_predict[clave][k]]\n",
    "    \n",
    "    df_to_predict = df2.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "       \n",
    "    X_train = df\n",
    "    Y_train = X_train.price_aprox_usd\n",
    "    X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=0)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    total_predicciones = rf.predict(df_to_predict)\n",
    "     \n",
    "    i = 0\n",
    "    for punto in dic_clusters_predict[clave]:\n",
    "        if i < len(total_predicciones):\n",
    "            predict_set_aux.loc[punto, 'prediccion'] = total_predicciones[i]\n",
    "        i += 1\n",
    "#Reabro el csv para obtener los ids        \n",
    "predict_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_predict.csv')\n",
    "ids = predict_set.id\n",
    "predicciones = predict_set_aux.prediccion\n",
    "resultado = pd.DataFrame({'id': ids, 'price_usd' : predicciones})\n",
    "resultado.to_csv(\"prediccion2.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means + KNN + Random Forest regression (ganador por ahora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_train.csv')\n",
    "train_set = train_set.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "       'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "       'rooms', 'expenses','price_aprox_usd']]\n",
    "\n",
    "#Saco las ultimas dos filas por un tema de división del dataset en partes para el entrenamiento\n",
    "train_set.drop(train_set.index[78656], inplace=True)\n",
    "train_set.drop(train_set.index[78655], inplace=True)\n",
    "\n",
    "df_to_predict = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_predict.csv')\n",
    "predic_set = df_to_predict.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "\n",
    "train_set_aux = train_set.copy()\n",
    "\n",
    "import numpy as np\n",
    "def setear_en_cero(row): return 0\n",
    "train_set_aux['knn'] = train_set_aux.apply(lambda row: setear_en_cero(row),axis=1)\n",
    "\n",
    "puntos_division = len(train_set) // 5\n",
    "\n",
    "z=0\n",
    "j = puntos_division\n",
    "total_pred = []\n",
    "for x in range(5): \n",
    "    train_set_temporal = train_set[z:j]\n",
    "    train_set_temporal = train_set_temporal.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "    frames = [train_set[:z], train_set[j:]]\n",
    "    X_train = pd.concat(frames)\n",
    "    X_train = X_train.astype(int)\n",
    "    Y_train = X_train.price_aprox_usd\n",
    "    X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "    neigh = KNeighborsClassifier(n_neighbors=100)\n",
    "    neigh.fit(X_train, Y_train) \n",
    "    prediccion = neigh.predict(train_set_temporal)\n",
    "    prediccion = prediccion.tolist()\n",
    "    total_pred += prediccion\n",
    "train_set_aux['knn'] = total_pred\n",
    "\n",
    "\n",
    "#Clasifico con knn a los datos a predecir\n",
    "predic_set = df_to_predict.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "X_train = train_set[:]\n",
    "X_train = X_train.astype(int)\n",
    "Y_train = X_train.price_aprox_usd\n",
    "X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses',]]\n",
    "neigh = KNeighborsClassifier(n_neighbors=15)\n",
    "neigh.fit(X_train, Y_train) \n",
    "prediccion = neigh.predict(predic_set)\n",
    "prediccion = prediccion.tolist()\n",
    "\n",
    "predic_set['knn'] = prediccion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hago K-means para el dataset de entrenamiento\n",
    "\n",
    "\n",
    "# Object KMeans\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=6, init=\"k-means++\", n_init=10, max_iter=500, tol=0.0001, \n",
    "                        precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans.fit(train_set_aux)\n",
    "\n",
    "dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "\n",
    "#Hago K-means para el dataset de validación\n",
    "\n",
    "predict_set_aux = predic_set\n",
    "\n",
    "import numpy as np\n",
    "def setear_en_cero(row): return 0\n",
    "#Columna que luego será llenada con las predicciones\n",
    "predict_set_aux['prediccion'] = predict_set_aux.apply(lambda row: setear_en_cero(row),axis=1)\n",
    "\n",
    "# Object KMeans\n",
    "kmeans2 = sklearn.cluster.KMeans(n_clusters=6, init=\"k-means++\", n_init=10, max_iter=500, tol=0.0001, \n",
    "                        precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans2.fit(predict_set_aux)\n",
    "\n",
    "dic_clusters_predict = {i: np.where(kmeans2.labels_ == i)[0] for i in range(kmeans2.n_clusters)}\n",
    "\n",
    "#Una vez que se los clusters de cada dato extraigo del dataset de entrenamiento los datos del cluster 0 y los uso para predecir\n",
    "#los datos del dataset de predicción pertenecientes también al cluster 0. Luego repito procedimiento para cada cluster.\n",
    "for clave in dic_clusters:\n",
    "    \n",
    "    #Creación de datasets donde se almacenarán los datos de cada dataset pertenecientes a determinado cluster (según la iteración)\n",
    "    df = pd.DataFrame(columns=['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','price_aprox_usd'])\n",
    "    df2 = pd.DataFrame(columns=['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses'])\n",
    "    \n",
    "    for j in range(0,len(dic_clusters[clave])):\n",
    "        df.loc[j] = train_set_aux.loc[dic_clusters[clave][j]]\n",
    "        \n",
    "    \n",
    "    for k in range(0,len(dic_clusters_predict[clave])):\n",
    "        df2.loc[k] = predict_set_aux.loc[dic_clusters_predict[clave][k]]\n",
    "    \n",
    "    df_to_predict = df2.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "       \n",
    "    X_train = df\n",
    "    Y_train = X_train.price_aprox_usd\n",
    "    X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses']]\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=0)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    total_predicciones = rf.predict(df_to_predict)\n",
    "    \n",
    "    i = 0\n",
    "    for punto in dic_clusters_predict[clave]:\n",
    "        if i < len(total_predicciones):\n",
    "            predict_set_aux.loc[punto, 'prediccion'] = total_predicciones[i]\n",
    "        i += 1\n",
    "#Reabro el csv para obtener los ids        \n",
    "predict_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_predict.csv')\n",
    "ids = predict_set.id\n",
    "predicciones = predict_set_aux.prediccion\n",
    "resultado = pd.DataFrame({'id': ids, 'price_usd' : predicciones})\n",
    "resultado.to_csv(\"prediccion2.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K - Means usando los clusters como una columna más "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>property_type</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>place_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>description</th>\n",
       "      <th>floor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>expenses</th>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94953600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-35.050505</td>\n",
       "      <td>-59.710847</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23697.142857</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94953600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.603714</td>\n",
       "      <td>-58.381581</td>\n",
       "      <td>430</td>\n",
       "      <td>3</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94953600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-34.628492</td>\n",
       "      <td>-58.390903</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>219.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_on  property_type        lat        lon  place_name  state_name  \\\n",
       "0  94953600.0              2 -35.050505 -59.710847         156           3   \n",
       "1  94953600.0              1 -34.603714 -58.381581         430           3   \n",
       "2  94953600.0              4 -34.628492 -58.390903         179           3   \n",
       "\n",
       "   surface_total_in_m2  surface_covered_in_m2  description  floor  rooms  \\\n",
       "0               1132.0                  251.0           20    1.0    3.0   \n",
       "1                 52.0                   52.0           20    1.0    1.0   \n",
       "2                219.0                  190.0            0    1.0    3.0   \n",
       "\n",
       "       expenses  price_aprox_usd  cluster  \n",
       "0  23697.142857         440000.0      8.0  \n",
       "1     10.000000         125000.0      8.0  \n",
       "2  45000.000000         240000.0      8.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_train.csv')\n",
    "train_set = train_set.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "       'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "       'rooms', 'expenses','price_aprox_usd']]\n",
    "\n",
    "N_CLUSTERS = 15 ; MAX_ITER = 500\n",
    "def print_results(centroids, num_cluster_points):\n",
    "    print('\\n\\nFINAL RESULT:')\n",
    "    for i, c in enumerate(centroids):\n",
    "        print('\\tCluster %d' % (i + 1))\n",
    "        print('\\t\\tNumber Points in Cluster %d' % num_cluster_points.count(i))\n",
    "        print('\\t\\tCentroid: %s' % str(centroids[i]))\n",
    "\n",
    "\n",
    "\n",
    "# Object KMeans\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=N_CLUSTERS, init=\"k-means++\", n_init=10, max_iter=MAX_ITER, tol=0.0001, \n",
    "                precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans.fit(train_set)\n",
    "dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "for clave,valor in dic_clusters.items():\n",
    "    train_set.loc[valor, 'cluster'] = clave\n",
    "train_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_set[:]\n",
    "Y_train = X_train.price_aprox_usd\n",
    "X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','cluster']]\n",
    "\n",
    "df_to_predict = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_predict.csv')\n",
    "# Object KMeans\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=N_CLUSTERS, init=\"k-means++\", n_init=10, max_iter=MAX_ITER, tol=0.0001, \n",
    "                precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans.fit(df_to_predict)\n",
    "\n",
    "#Creo la columna de los clusters para el ds con los datos a predecir\n",
    "dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "for clave,valor in dic_clusters.items():\n",
    "    df_to_predict.loc[valor, 'cluster'] = clave\n",
    "ids = df_to_predict.id\n",
    "\n",
    "df_to_predict = df_to_predict.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','cluster']]\n",
    "\n",
    "prediccion = linear_regression(df_to_predict, X_train, Y_train)\n",
    "resultado = pd.DataFrame({'id': ids, 'price_usd' : prediccion})\n",
    "resultado.to_csv(\"prediccion2.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando Random Forest regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=0)\n",
    "rf.fit(X_train, Y_train)\n",
    "predicted_test = rf.predict(df_to_predict)\n",
    "resultado = pd.DataFrame({'id': ids, 'price_usd' : predicted_test})\n",
    "resultado.to_csv(\"prediccion2.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K - Means + KNN + Random Forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Repito proceso de asignarle a los datasets la columna con los clusters\n",
    "\n",
    "train_set = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_train.csv')\n",
    "train_set = train_set.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "       'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "       'rooms', 'expenses','price_aprox_usd']]\n",
    "\n",
    "#Saco las ultimas dos filas por un tema de división del dataset en partes para el entrenamiento\n",
    "train_set.drop(train_set.index[78656], inplace=True)\n",
    "train_set.drop(train_set.index[78655], inplace=True)\n",
    "\n",
    "N_CLUSTERS = 15 ; MAX_ITER = 500\n",
    "def print_results(centroids, num_cluster_points):\n",
    "    print('\\n\\nFINAL RESULT:')\n",
    "    for i, c in enumerate(centroids):\n",
    "        print('\\tCluster %d' % (i + 1))\n",
    "        print('\\t\\tNumber Points in Cluster %d' % num_cluster_points.count(i))\n",
    "        print('\\t\\tCentroid: %s' % str(centroids[i]))\n",
    "\n",
    "\n",
    "\n",
    "# Object KMeans\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=N_CLUSTERS, init=\"k-means++\", n_init=10, max_iter=MAX_ITER, tol=0.0001, \n",
    "                precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans.fit(train_set)\n",
    "\n",
    "dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "for clave,valor in dic_clusters.items():\n",
    "    train_set.loc[valor, 'cluster'] = clave\n",
    "    \n",
    "\n",
    "X_train = train_set[:]\n",
    "Y_train = X_train.price_aprox_usd\n",
    "X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','cluster']]\n",
    "\n",
    "df_to_predict = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_predict.csv')\n",
    "# Object KMeans\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=N_CLUSTERS, init=\"k-means++\", n_init=10, max_iter=MAX_ITER, tol=0.0001, \n",
    "                precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=\"auto\")\n",
    "\n",
    "# Calculate Kmeans\n",
    "kmeans.fit(df_to_predict)\n",
    "\n",
    "dic_clusters = {i: np.where(kmeans.labels_ == i)[0] for i in range(kmeans.n_clusters)}\n",
    "for clave,valor in dic_clusters.items():\n",
    "    df_to_predict.loc[valor, 'cluster'] = clave\n",
    "ids = df_to_predict.id\n",
    "\n",
    "#Copia donde tendré al dataset de entrenamiento con la columna de clusters y la clasificación por knn\n",
    "train_set_aux = train_set.copy()\n",
    "\n",
    "import numpy as np\n",
    "def setear_en_cero(row): return 0\n",
    "train_set_aux['knn'] = train_set_aux.apply(lambda row: setear_en_cero(row),axis=1)\n",
    "\n",
    "puntos_division = len(train_set) // 5\n",
    "\n",
    "z=0\n",
    "j = puntos_division\n",
    "total_pred = []\n",
    "for x in range(5): \n",
    "    train_set_temporal = train_set[z:j]\n",
    "    train_set_temporal = train_set_temporal.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','cluster']]\n",
    "    frames = [train_set[:z], train_set[j:]]\n",
    "    X_train = pd.concat(frames)\n",
    "    X_train = X_train.astype(int)\n",
    "    Y_train = X_train.price_aprox_usd\n",
    "    X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','cluster']]\n",
    "    neigh = KNeighborsClassifier(n_neighbors=100)\n",
    "    neigh.fit(X_train, Y_train) \n",
    "    prediccion = neigh.predict(train_set_temporal)\n",
    "    prediccion = prediccion.tolist()\n",
    "    total_pred += prediccion\n",
    "train_set_aux['knn'] = total_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clasifico con knn a los datos a predecir\n",
    "predic_set = df_to_predict.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','cluster']]\n",
    "X_train = train_set[:]\n",
    "X_train = X_train.astype(int)\n",
    "Y_train = X_train.price_aprox_usd\n",
    "X_train = X_train.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','cluster']]\n",
    "neigh = KNeighborsClassifier(n_neighbors=15)\n",
    "neigh.fit(X_train, Y_train) \n",
    "prediccion = neigh.predict(predic_set)\n",
    "prediccion = prediccion.tolist()\n",
    "\n",
    "predic_set['knn'] = prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train= train_set_aux.price_aprox_usd\n",
    "X_train = train_set_aux.loc[:,['created_on', 'property_type', 'lat', 'lon', 'place_name', 'state_name',\n",
    "               'surface_total_in_m2', 'surface_covered_in_m2', 'description', 'floor',\n",
    "               'rooms', 'expenses','knn','cluster']]\n",
    "\n",
    "#Predigo con random forest regressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=0)\n",
    "rf.fit(X_train, Y_train)\n",
    "predicted_test = rf.predict(predic_set)\n",
    "resultado = pd.DataFrame({'id': ids, 'price_usd' : predicted_test})\n",
    "resultado.to_csv(\"prediccion4.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haciendo un dataset con bins para el intento fallido de random forests clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>property_type</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>place_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>description</th>\n",
       "      <th>floor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>expenses</th>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <th>price_usd_per_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94953600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-35.050505</td>\n",
       "      <td>-59.710847</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23697.142857</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>388.692580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94953600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.603714</td>\n",
       "      <td>-58.381581</td>\n",
       "      <td>430</td>\n",
       "      <td>3</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>2403.846154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_on  property_type        lat        lon  place_name  state_name  \\\n",
       "0  94953600.0              2 -35.050505 -59.710847         156           3   \n",
       "1  94953600.0              1 -34.603714 -58.381581         430           3   \n",
       "\n",
       "   surface_total_in_m2  surface_covered_in_m2  description  floor  rooms  \\\n",
       "0               1132.0                  251.0           20    1.0    3.0   \n",
       "1                 52.0                   52.0           20    1.0    1.0   \n",
       "\n",
       "       expenses  price_aprox_usd  price_usd_per_m2  \n",
       "0  23697.142857         440000.0        388.692580  \n",
       "1     10.000000         125000.0       2403.846154  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_bins = pd.read_csv('Desktop/Datos/tp2/data_filled_ready_to_train.csv')\n",
    "ds_bins.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>property_type</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>place_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>description</th>\n",
       "      <th>floor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>expenses</th>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94953600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-35.050505</td>\n",
       "      <td>-59.710847</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23697.142857</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>388.692580</td>\n",
       "      <td>(226.922, 628.764]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94953600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.603714</td>\n",
       "      <td>-58.381581</td>\n",
       "      <td>430</td>\n",
       "      <td>3</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>2403.846154</td>\n",
       "      <td>(2250.0, 2526.316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94953600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-34.628492</td>\n",
       "      <td>-58.390903</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>219.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>1095.890411</td>\n",
       "      <td>(1000.0, 1304.348]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_on  property_type        lat        lon  place_name  state_name  \\\n",
       "0  94953600.0              2 -35.050505 -59.710847         156           3   \n",
       "1  94953600.0              1 -34.603714 -58.381581         430           3   \n",
       "2  94953600.0              4 -34.628492 -58.390903         179           3   \n",
       "\n",
       "   surface_total_in_m2  surface_covered_in_m2  description  floor  rooms  \\\n",
       "0               1132.0                  251.0           20    1.0    3.0   \n",
       "1                 52.0                   52.0           20    1.0    1.0   \n",
       "2                219.0                  190.0            0    1.0    3.0   \n",
       "\n",
       "       expenses  price_aprox_usd  price_usd_per_m2                 bin  \n",
       "0  23697.142857         440000.0        388.692580  (226.922, 628.764]  \n",
       "1     10.000000         125000.0       2403.846154  (2250.0, 2526.316]  \n",
       "2  45000.000000         240000.0       1095.890411  (1000.0, 1304.348]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properati_bins = ds_bins.loc[ds_bins.price_usd_per_m2 > 2,:]\n",
    "properati_bins = ds_bins.loc[ds_bins.price_usd_per_m2 < 61900.0,:]\n",
    "properati_bins['bin'] = pd.qcut(properati_bins.price_usd_per_m2,10)\n",
    "properati_bins.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properati_bins = properati_bins.loc[:,['FECHA','property_type','state_name','lat','lon','surface_total_in_m2','surface_covered_in_m2','bin']]\n",
    "properati_bins = properati_bins[:14000]\n",
    "properati_bins.to_csv(\"filtradobinsgrande.csv\",encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
